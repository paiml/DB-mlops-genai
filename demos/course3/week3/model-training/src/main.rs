//! ML Model Training and Registry Demo
//!
//! Demonstrates ML training with aprender and model management with pacha.
//! Compare with Databricks AutoML and Unity Catalog Model Registry.
//!
//! # Course 3, Week 3: Model Training and Registry

use rand::Rng;
use serde::{Deserialize, Serialize};
use std::time::Instant;
use thiserror::Error;

// ============================================================================
// Error Types
// ============================================================================

#[derive(Error, Debug)]
pub enum ModelError {
    #[error("Training error: {0}")]
    Training(String),

    #[error("Registry error: {0}")]
    Registry(String),

    #[error("Serialization error: {0}")]
    Serialization(#[from] serde_json::Error),
}

// ============================================================================
// Dataset Generation
// ============================================================================

/// A simple dataset for training
#[derive(Debug, Clone)]
pub struct Dataset {
    pub features: Vec<Vec<f64>>,
    pub labels: Vec<f64>,
    pub feature_names: Vec<String>,
}

impl Dataset {
    /// Generate a synthetic classification dataset
    pub fn generate_classification(n_samples: usize, n_features: usize, _seed: u64) -> Self {
        let mut rng = rand::thread_rng();

        let feature_names: Vec<String> =
            (0..n_features).map(|i| format!("feature_{}", i)).collect();

        let mut features = Vec::with_capacity(n_samples);
        let mut labels = Vec::with_capacity(n_samples);

        for i in 0..n_samples {
            let mut row = Vec::with_capacity(n_features);
            let mut sum = 0.0;

            for j in 0..n_features {
                let val = rng.gen::<f64>() * 2.0 - 1.0 + (i as f64 * 0.001);
                row.push(val);
                sum += val * (j as f64 + 1.0);
            }

            features.push(row);
            // Binary classification based on weighted sum
            labels.push(if sum > 0.0 { 1.0 } else { 0.0 });
        }

        Self {
            features,
            labels,
            feature_names,
        }
    }

    /// Generate a synthetic regression dataset
    pub fn generate_regression(n_samples: usize, n_features: usize, _seed: u64) -> Self {
        let mut rng = rand::thread_rng();

        let feature_names: Vec<String> =
            (0..n_features).map(|i| format!("feature_{}", i)).collect();

        let mut features = Vec::with_capacity(n_samples);
        let mut labels = Vec::with_capacity(n_samples);

        // Generate true coefficients
        let coeffs: Vec<f64> = (0..n_features).map(|i| (i as f64 + 1.0) * 0.5).collect();

        for _ in 0..n_samples {
            let mut row = Vec::with_capacity(n_features);
            let mut y = rng.gen::<f64>() * 0.1; // noise

            for (_j, &coeff) in coeffs.iter().enumerate() {
                let val = rng.gen::<f64>() * 2.0 - 1.0;
                row.push(val);
                y += val * coeff;
            }

            features.push(row);
            labels.push(y);
        }

        Self {
            features,
            labels,
            feature_names,
        }
    }

    /// Split dataset into train and test
    pub fn train_test_split(&self, test_ratio: f64) -> (Dataset, Dataset) {
        let n_test = (self.features.len() as f64 * test_ratio) as usize;
        let n_train = self.features.len() - n_test;

        let train = Dataset {
            features: self.features[..n_train].to_vec(),
            labels: self.labels[..n_train].to_vec(),
            feature_names: self.feature_names.clone(),
        };

        let test = Dataset {
            features: self.features[n_train..].to_vec(),
            labels: self.labels[n_train..].to_vec(),
            feature_names: self.feature_names.clone(),
        };

        (train, test)
    }
}

// ============================================================================
// Simple Models (Pure Rust implementations for understanding)
// ============================================================================

/// Linear regression model
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LinearRegression {
    pub weights: Vec<f64>,
    pub bias: f64,
    pub learning_rate: f64,
    pub n_iterations: usize,
}

impl LinearRegression {
    pub fn new(n_features: usize, learning_rate: f64, n_iterations: usize) -> Self {
        Self {
            weights: vec![0.0; n_features],
            bias: 0.0,
            learning_rate,
            n_iterations,
        }
    }

    /// Train using gradient descent
    pub fn fit(&mut self, features: &[Vec<f64>], labels: &[f64]) {
        let n_samples = features.len() as f64;

        for _ in 0..self.n_iterations {
            let mut weight_gradients = vec![0.0; self.weights.len()];
            let mut bias_gradient = 0.0;

            for (x, &y) in features.iter().zip(labels.iter()) {
                let pred = self.predict_single(x);
                let error = pred - y;

                for (j, &xj) in x.iter().enumerate() {
                    weight_gradients[j] += error * xj;
                }
                bias_gradient += error;
            }

            for (w, grad) in self.weights.iter_mut().zip(weight_gradients.iter()) {
                *w -= self.learning_rate * grad / n_samples;
            }
            self.bias -= self.learning_rate * bias_gradient / n_samples;
        }
    }

    fn predict_single(&self, x: &[f64]) -> f64 {
        let mut pred = self.bias;
        for (w, xj) in self.weights.iter().zip(x.iter()) {
            pred += w * xj;
        }
        pred
    }

    pub fn predict(&self, features: &[Vec<f64>]) -> Vec<f64> {
        features.iter().map(|x| self.predict_single(x)).collect()
    }

    /// Calculate RÂ² score
    pub fn score(&self, features: &[Vec<f64>], labels: &[f64]) -> f64 {
        let predictions = self.predict(features);
        let mean_y: f64 = labels.iter().sum::<f64>() / labels.len() as f64;

        let ss_tot: f64 = labels.iter().map(|&y| (y - mean_y).powi(2)).sum();
        let ss_res: f64 = predictions
            .iter()
            .zip(labels.iter())
            .map(|(&pred, &y)| (y - pred).powi(2))
            .sum();

        1.0 - ss_res / ss_tot
    }
}

/// Simple decision tree for classification
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DecisionStump {
    pub feature_index: usize,
    pub threshold: f64,
    pub left_class: f64,
    pub right_class: f64,
}

impl DecisionStump {
    /// Find the best split
    pub fn fit(features: &[Vec<f64>], labels: &[f64]) -> Self {
        let n_features = features[0].len();
        let mut best_feature = 0;
        let mut best_threshold = 0.0;
        let mut best_gini = f64::MAX;

        for feat_idx in 0..n_features {
            // Get unique thresholds
            let mut values: Vec<f64> = features.iter().map(|x| x[feat_idx]).collect();
            values.sort_by(|a, b| a.partial_cmp(b).unwrap());
            values.dedup();

            for &thresh in &values {
                let gini = Self::gini_impurity(features, labels, feat_idx, thresh);
                if gini < best_gini {
                    best_gini = gini;
                    best_feature = feat_idx;
                    best_threshold = thresh;
                }
            }
        }

        // Determine class for each side
        let mut left_labels = Vec::new();
        let mut right_labels = Vec::new();

        for (x, &label) in features.iter().zip(labels.iter()) {
            if x[best_feature] <= best_threshold {
                left_labels.push(label);
            } else {
                right_labels.push(label);
            }
        }

        let left_class = Self::majority_class(&left_labels);
        let right_class = Self::majority_class(&right_labels);

        Self {
            feature_index: best_feature,
            threshold: best_threshold,
            left_class,
            right_class,
        }
    }

    fn gini_impurity(
        features: &[Vec<f64>],
        labels: &[f64],
        feat_idx: usize,
        threshold: f64,
    ) -> f64 {
        let mut left_counts = [0usize; 2];
        let mut right_counts = [0usize; 2];

        for (x, &y) in features.iter().zip(labels.iter()) {
            let class = y as usize;
            if x[feat_idx] <= threshold {
                left_counts[class.min(1)] += 1;
            } else {
                right_counts[class.min(1)] += 1;
            }
        }

        let left_total = left_counts.iter().sum::<usize>() as f64;
        let right_total = right_counts.iter().sum::<usize>() as f64;
        let total = left_total + right_total;

        if left_total == 0.0 || right_total == 0.0 {
            return f64::MAX;
        }

        let left_gini = 1.0
            - left_counts
                .iter()
                .map(|&c| (c as f64 / left_total).powi(2))
                .sum::<f64>();
        let right_gini = 1.0
            - right_counts
                .iter()
                .map(|&c| (c as f64 / right_total).powi(2))
                .sum::<f64>();

        (left_total / total) * left_gini + (right_total / total) * right_gini
    }

    fn majority_class(labels: &[f64]) -> f64 {
        if labels.is_empty() {
            return 0.0;
        }
        let sum: f64 = labels.iter().sum();
        if sum > labels.len() as f64 / 2.0 {
            1.0
        } else {
            0.0
        }
    }

    pub fn predict(&self, features: &[Vec<f64>]) -> Vec<f64> {
        features
            .iter()
            .map(|x| {
                if x[self.feature_index] <= self.threshold {
                    self.left_class
                } else {
                    self.right_class
                }
            })
            .collect()
    }

    pub fn accuracy(&self, features: &[Vec<f64>], labels: &[f64]) -> f64 {
        let predictions = self.predict(features);
        let correct = predictions
            .iter()
            .zip(labels.iter())
            .filter(|(&pred, &label)| (pred - label).abs() < 0.5)
            .count();
        correct as f64 / labels.len() as f64
    }
}

// ============================================================================
// Model Card (for registry)
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelCard {
    pub name: String,
    pub version: String,
    pub model_type: String,
    pub description: String,
    pub metrics: std::collections::HashMap<String, f64>,
    pub parameters: std::collections::HashMap<String, String>,
    pub created_at: String,
    pub author: String,
}

impl ModelCard {
    pub fn new(name: &str, model_type: &str, description: &str) -> Self {
        Self {
            name: name.to_string(),
            version: "1.0.0".to_string(),
            model_type: model_type.to_string(),
            description: description.to_string(),
            metrics: std::collections::HashMap::new(),
            parameters: std::collections::HashMap::new(),
            created_at: chrono_lite_now(),
            author: "sovereign-ai".to_string(),
        }
    }

    pub fn add_metric(&mut self, key: &str, value: f64) -> &mut Self {
        self.metrics.insert(key.to_string(), value);
        self
    }

    pub fn add_param(&mut self, key: &str, value: &str) -> &mut Self {
        self.parameters.insert(key.to_string(), value.to_string());
        self
    }
}

fn chrono_lite_now() -> String {
    // Simple timestamp without chrono dependency
    format!(
        "{}",
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs()
    )
}

// ============================================================================
// Demo
// ============================================================================

fn main() {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘     Model Training & Registry - Course 3, Week 3              â•‘");
    println!("â•‘     ML with aprender concepts, Registry with pacha concepts   â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    // -------------------------------------------------------------------------
    // Demo 1: Linear Regression
    // -------------------------------------------------------------------------
    println!("\nğŸ“Š Demo 1: Linear Regression");
    println!("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    let dataset = Dataset::generate_regression(1000, 5, 42);
    let (train, test) = dataset.train_test_split(0.2);

    println!("   Training samples: {}", train.features.len());
    println!("   Test samples: {}", test.features.len());
    println!("   Features: {}", train.feature_names.len());

    let start = Instant::now();
    let mut lr_model = LinearRegression::new(5, 0.01, 1000);
    lr_model.fit(&train.features, &train.labels);
    let train_time = start.elapsed();

    let train_score = lr_model.score(&train.features, &train.labels);
    let test_score = lr_model.score(&test.features, &test.labels);

    println!("   Training time: {:?}", train_time);
    println!("   Train RÂ²: {:.4}", train_score);
    println!("   Test RÂ²:  {:.4}", test_score);

    // Create model card
    let mut lr_card = ModelCard::new(
        "linear-regression-v1",
        "LinearRegression",
        "Linear regression for numeric prediction",
    );
    lr_card
        .add_metric("train_r2", train_score)
        .add_metric("test_r2", test_score)
        .add_param("learning_rate", "0.01")
        .add_param("n_iterations", "1000");

    println!("\n   ğŸ“‹ Model Card:");
    println!("   {}", serde_json::to_string_pretty(&lr_card).unwrap());

    // -------------------------------------------------------------------------
    // Demo 2: Decision Tree (Stump) Classification
    // -------------------------------------------------------------------------
    println!("\nğŸ“Š Demo 2: Decision Tree Classification");
    println!("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    let dataset = Dataset::generate_classification(1000, 5, 42);
    let (train, test) = dataset.train_test_split(0.2);

    println!("   Training samples: {}", train.features.len());
    println!("   Test samples: {}", test.features.len());

    let start = Instant::now();
    let tree = DecisionStump::fit(&train.features, &train.labels);
    let train_time = start.elapsed();

    let train_acc = tree.accuracy(&train.features, &train.labels);
    let test_acc = tree.accuracy(&test.features, &test.labels);

    println!("   Training time: {:?}", train_time);
    println!(
        "   Split: feature_{} <= {:.4}",
        tree.feature_index, tree.threshold
    );
    println!("   Train accuracy: {:.4}", train_acc);
    println!("   Test accuracy:  {:.4}", test_acc);

    // Create model card
    let mut tree_card = ModelCard::new(
        "decision-stump-v1",
        "DecisionStump",
        "Single-split decision tree for binary classification",
    );
    tree_card
        .add_metric("train_accuracy", train_acc)
        .add_metric("test_accuracy", test_acc)
        .add_param("feature_index", &tree.feature_index.to_string())
        .add_param("threshold", &format!("{:.4}", tree.threshold));

    // -------------------------------------------------------------------------
    // Demo 3: Model Serialization (pacha concepts)
    // -------------------------------------------------------------------------
    println!("\nğŸ“¦ Demo 3: Model Serialization");
    println!("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    let model_json = serde_json::to_string(&lr_model).unwrap();
    println!("   Serialized model size: {} bytes", model_json.len());

    // Simulate BLAKE3 hash (pacha uses this for content addressing)
    let model_hash = simple_hash(&model_json);
    println!("   Model hash (simulated): {}", model_hash);

    println!("\n   ğŸ“ Registry Entry:");
    println!("   {{");
    println!("     \"name\": \"{}\",", lr_card.name);
    println!("     \"version\": \"{}\",", lr_card.version);
    println!("     \"hash\": \"{}\",", model_hash);
    println!("     \"metrics\": {:?}", lr_card.metrics);
    println!("   }}");

    // -------------------------------------------------------------------------
    // Summary
    // -------------------------------------------------------------------------
    println!("\nâœ… Demo complete!");
    println!("\nğŸ“– Key Concepts:");
    println!("   - aprender: Pure Rust ML algorithms (regression, trees, clustering)");
    println!("   - pacha: Model registry with signing, versioning, content addressing");
    println!("   - Model cards: Metadata for reproducibility and governance");
    println!("   - Compare with Databricks AutoML + Unity Catalog Model Registry");
}

/// Simple hash function (pacha uses BLAKE3)
fn simple_hash(data: &str) -> String {
    let mut hash: u64 = 0;
    for byte in data.bytes() {
        hash = hash.wrapping_mul(31).wrapping_add(byte as u64);
    }
    format!("{:016x}", hash)
}

// ============================================================================
// Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    // =========================================================================
    // Dataset Tests
    // =========================================================================

    #[test]
    fn test_dataset_generation() {
        let dataset = Dataset::generate_regression(100, 5, 42);
        assert_eq!(dataset.features.len(), 100);
        assert_eq!(dataset.labels.len(), 100);
        assert_eq!(dataset.feature_names.len(), 5);
    }

    #[test]
    fn test_dataset_classification() {
        let dataset = Dataset::generate_classification(100, 4, 42);
        assert_eq!(dataset.features.len(), 100);
        assert_eq!(dataset.labels.len(), 100);
        assert_eq!(dataset.feature_names.len(), 4);
        // Labels should be binary
        for label in &dataset.labels {
            assert!(*label == 0.0 || *label == 1.0);
        }
    }

    #[test]
    fn test_dataset_feature_names() {
        let dataset = Dataset::generate_regression(10, 3, 42);
        assert_eq!(
            dataset.feature_names,
            vec!["feature_0", "feature_1", "feature_2"]
        );
    }

    #[test]
    fn test_train_test_split() {
        let dataset = Dataset::generate_regression(100, 5, 42);
        let (train, test) = dataset.train_test_split(0.2);
        assert_eq!(train.features.len(), 80);
        assert_eq!(test.features.len(), 20);
    }

    #[test]
    fn test_train_test_split_preserves_feature_names() {
        let dataset = Dataset::generate_regression(100, 3, 42);
        let (train, test) = dataset.train_test_split(0.3);
        assert_eq!(train.feature_names, dataset.feature_names);
        assert_eq!(test.feature_names, dataset.feature_names);
    }

    #[test]
    fn test_train_test_split_zero_ratio() {
        let dataset = Dataset::generate_regression(100, 3, 42);
        let (train, test) = dataset.train_test_split(0.0);
        assert_eq!(train.features.len(), 100);
        assert_eq!(test.features.len(), 0);
    }

    #[test]
    fn test_dataset_clone() {
        let dataset = Dataset::generate_regression(10, 2, 42);
        let cloned = dataset.clone();
        assert_eq!(dataset.features.len(), cloned.features.len());
        assert_eq!(dataset.labels.len(), cloned.labels.len());
    }

    // =========================================================================
    // Linear Regression Tests
    // =========================================================================

    #[test]
    fn test_linear_regression() {
        let dataset = Dataset::generate_regression(100, 3, 42);
        let mut model = LinearRegression::new(3, 0.1, 100);
        model.fit(&dataset.features, &dataset.labels);

        let score = model.score(&dataset.features, &dataset.labels);
        assert!(score > 0.5, "RÂ² should be reasonable: {}", score);
    }

    #[test]
    fn test_linear_regression_new() {
        let model = LinearRegression::new(5, 0.01, 500);
        assert_eq!(model.weights.len(), 5);
        assert_eq!(model.bias, 0.0);
        assert_eq!(model.learning_rate, 0.01);
        assert_eq!(model.n_iterations, 500);
    }

    #[test]
    fn test_linear_regression_predict() {
        let mut model = LinearRegression::new(2, 0.1, 1);
        model.weights = vec![1.0, 2.0];
        model.bias = 0.5;

        let predictions = model.predict(&[vec![1.0, 1.0], vec![2.0, 2.0]]);
        assert_eq!(predictions.len(), 2);
        assert!((predictions[0] - 3.5).abs() < 0.001); // 1*1 + 2*1 + 0.5 = 3.5
        assert!((predictions[1] - 6.5).abs() < 0.001); // 1*2 + 2*2 + 0.5 = 6.5
    }

    #[test]
    fn test_linear_regression_score_perfect() {
        let mut model = LinearRegression::new(2, 0.1, 1);
        model.weights = vec![1.0, 0.0];
        model.bias = 0.0;

        let features = vec![vec![0.0, 0.0], vec![1.0, 0.0], vec![2.0, 0.0]];
        let labels = vec![0.0, 1.0, 2.0];
        let score = model.score(&features, &labels);
        assert!((score - 1.0).abs() < 0.001);
    }

    #[test]
    fn test_linear_regression_clone() {
        let model = LinearRegression::new(3, 0.05, 200);
        let cloned = model.clone();
        assert_eq!(model.weights.len(), cloned.weights.len());
        assert_eq!(model.bias, cloned.bias);
    }

    #[test]
    fn test_linear_regression_serialization() {
        let model = LinearRegression::new(3, 0.01, 100);
        let json = serde_json::to_string(&model).unwrap();
        let deserialized: LinearRegression = serde_json::from_str(&json).unwrap();
        assert_eq!(model.weights.len(), deserialized.weights.len());
        assert_eq!(model.learning_rate, deserialized.learning_rate);
    }

    // =========================================================================
    // Decision Stump Tests
    // =========================================================================

    #[test]
    fn test_decision_stump() {
        let dataset = Dataset::generate_classification(100, 3, 42);
        let tree = DecisionStump::fit(&dataset.features, &dataset.labels);

        let accuracy = tree.accuracy(&dataset.features, &dataset.labels);
        assert!(
            accuracy > 0.5,
            "Accuracy should be better than random: {}",
            accuracy
        );
    }

    #[test]
    fn test_decision_stump_predict() {
        let tree = DecisionStump {
            feature_index: 0,
            threshold: 0.5,
            left_class: 0.0,
            right_class: 1.0,
        };

        let features = vec![vec![0.3], vec![0.7]];
        let predictions = tree.predict(&features);
        assert_eq!(predictions, vec![0.0, 1.0]);
    }

    #[test]
    fn test_decision_stump_accuracy_perfect() {
        let tree = DecisionStump {
            feature_index: 0,
            threshold: 0.5,
            left_class: 0.0,
            right_class: 1.0,
        };

        let features = vec![vec![0.3], vec![0.7]];
        let labels = vec![0.0, 1.0];
        let accuracy = tree.accuracy(&features, &labels);
        assert!((accuracy - 1.0).abs() < 0.001);
    }

    #[test]
    fn test_decision_stump_serialization() {
        let tree = DecisionStump {
            feature_index: 2,
            threshold: 0.75,
            left_class: 0.0,
            right_class: 1.0,
        };

        let json = serde_json::to_string(&tree).unwrap();
        let deserialized: DecisionStump = serde_json::from_str(&json).unwrap();
        assert_eq!(tree.feature_index, deserialized.feature_index);
        assert_eq!(tree.threshold, deserialized.threshold);
    }

    #[test]
    fn test_decision_stump_clone() {
        let tree = DecisionStump {
            feature_index: 1,
            threshold: 0.5,
            left_class: 0.0,
            right_class: 1.0,
        };

        let cloned = tree.clone();
        assert_eq!(tree.feature_index, cloned.feature_index);
    }

    // =========================================================================
    // Model Card Tests
    // =========================================================================

    #[test]
    fn test_model_card() {
        let mut card = ModelCard::new("test-model", "LinearRegression", "Test");
        card.add_metric("accuracy", 0.95);
        card.add_param("learning_rate", "0.01");

        assert_eq!(card.metrics.get("accuracy"), Some(&0.95));
        assert_eq!(
            card.parameters.get("learning_rate"),
            Some(&"0.01".to_string())
        );
    }

    #[test]
    fn test_model_card_new() {
        let card = ModelCard::new("fraud-detector", "DecisionTree", "Detects fraud");
        assert_eq!(card.name, "fraud-detector");
        assert_eq!(card.model_type, "DecisionTree");
        assert_eq!(card.description, "Detects fraud");
        assert_eq!(card.version, "1.0.0");
        assert_eq!(card.author, "sovereign-ai");
    }

    #[test]
    fn test_model_card_chained_methods() {
        let mut card = ModelCard::new("model", "Type", "Desc");
        card.add_metric("a", 1.0)
            .add_metric("b", 2.0)
            .add_param("x", "1")
            .add_param("y", "2");

        assert_eq!(card.metrics.len(), 2);
        assert_eq!(card.parameters.len(), 2);
    }

    #[test]
    fn test_model_card_serialization() {
        let mut card = ModelCard::new("test", "Linear", "Test model");
        card.add_metric("r2", 0.95);

        let json = serde_json::to_string(&card).unwrap();
        let deserialized: ModelCard = serde_json::from_str(&json).unwrap();
        assert_eq!(card.name, deserialized.name);
        assert_eq!(card.metrics.get("r2"), deserialized.metrics.get("r2"));
    }

    #[test]
    fn test_model_card_clone() {
        let mut card = ModelCard::new("test", "Linear", "Test");
        card.add_metric("acc", 0.9);
        let cloned = card.clone();
        assert_eq!(card.name, cloned.name);
        assert_eq!(card.metrics.get("acc"), cloned.metrics.get("acc"));
    }

    // =========================================================================
    // Error Tests
    // =========================================================================

    #[test]
    fn test_error_training() {
        let err = ModelError::Training("gradient explosion".to_string());
        assert!(err.to_string().contains("gradient explosion"));
    }

    #[test]
    fn test_error_registry() {
        let err = ModelError::Registry("model not found".to_string());
        assert!(err.to_string().contains("model not found"));
    }

    #[test]
    fn test_error_serialization() {
        let json_err = serde_json::from_str::<ModelCard>("invalid json");
        assert!(json_err.is_err());
        let err = ModelError::from(json_err.unwrap_err());
        assert!(err.to_string().contains("Serialization"));
    }

    #[test]
    fn test_error_debug() {
        let err = ModelError::Training("test".to_string());
        let debug_str = format!("{:?}", err);
        assert!(debug_str.contains("Training"));
    }

    // =========================================================================
    // Hash Tests
    // =========================================================================

    #[test]
    fn test_simple_hash_deterministic() {
        let hash1 = simple_hash("test data");
        let hash2 = simple_hash("test data");
        assert_eq!(hash1, hash2);
    }

    #[test]
    fn test_simple_hash_different_inputs() {
        let hash1 = simple_hash("data1");
        let hash2 = simple_hash("data2");
        assert_ne!(hash1, hash2);
    }

    #[test]
    fn test_simple_hash_format() {
        let hash = simple_hash("test");
        assert_eq!(hash.len(), 16); // 16 hex chars for u64
    }

    // =========================================================================
    // Serialization Round-Trip Tests
    // =========================================================================

    #[test]
    fn test_model_serialization() {
        let model = LinearRegression::new(3, 0.01, 100);
        let json = serde_json::to_string(&model).unwrap();
        let deserialized: LinearRegression = serde_json::from_str(&json).unwrap();
        assert_eq!(model.weights.len(), deserialized.weights.len());
    }

    #[test]
    fn test_decision_stump_round_trip() {
        let dataset = Dataset::generate_classification(50, 2, 42);
        let tree = DecisionStump::fit(&dataset.features, &dataset.labels);

        let json = serde_json::to_string(&tree).unwrap();
        let restored: DecisionStump = serde_json::from_str(&json).unwrap();

        // Predictions should be identical
        let preds1 = tree.predict(&dataset.features);
        let preds2 = restored.predict(&dataset.features);
        assert_eq!(preds1, preds2);
    }
}
